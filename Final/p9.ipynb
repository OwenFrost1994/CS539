{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The results here may be different from the results in the total file of final exam. I rerunned for several times. So take the results here as the final results please."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('ctrain.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.585385</td>\n",
       "      <td>0.518833</td>\n",
       "      <td>0.457810</td>\n",
       "      <td>0.094280</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.705958</td>\n",
       "      <td>0.654958</td>\n",
       "      <td>0.514878</td>\n",
       "      <td>0.219656</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.579268</td>\n",
       "      <td>0.863228</td>\n",
       "      <td>0.437027</td>\n",
       "      <td>0.869473</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.951644</td>\n",
       "      <td>0.770822</td>\n",
       "      <td>0.078296</td>\n",
       "      <td>0.428559</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.499662</td>\n",
       "      <td>0.560521</td>\n",
       "      <td>0.630058</td>\n",
       "      <td>0.618843</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.752897</td>\n",
       "      <td>0.173620</td>\n",
       "      <td>0.718863</td>\n",
       "      <td>0.975656</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.601106</td>\n",
       "      <td>0.969755</td>\n",
       "      <td>0.590008</td>\n",
       "      <td>0.775430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.095425</td>\n",
       "      <td>0.871820</td>\n",
       "      <td>0.114290</td>\n",
       "      <td>0.777152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.284756</td>\n",
       "      <td>0.346061</td>\n",
       "      <td>0.534890</td>\n",
       "      <td>0.823065</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.190595</td>\n",
       "      <td>0.716755</td>\n",
       "      <td>0.101199</td>\n",
       "      <td>0.804759</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3  4  5\n",
       "0    0.585385  0.518833  0.457810  0.094280  0  1\n",
       "1    0.705958  0.654958  0.514878  0.219656  0  1\n",
       "2    0.579268  0.863228  0.437027  0.869473  0  1\n",
       "3    0.951644  0.770822  0.078296  0.428559  0  1\n",
       "4    0.499662  0.560521  0.630058  0.618843  0  1\n",
       "..        ...       ...       ...       ... .. ..\n",
       "145  0.752897  0.173620  0.718863  0.975656  1  0\n",
       "146  0.601106  0.969755  0.590008  0.775430  1  0\n",
       "147  0.095425  0.871820  0.114290  0.777152  1  0\n",
       "148  0.284756  0.346061  0.534890  0.823065  1  0\n",
       "149  0.190595  0.716755  0.101199  0.804759  1  0\n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('ctest.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.248782</td>\n",
       "      <td>0.876835</td>\n",
       "      <td>0.806854</td>\n",
       "      <td>0.020668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.057214</td>\n",
       "      <td>0.828857</td>\n",
       "      <td>0.617800</td>\n",
       "      <td>0.550427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.735268</td>\n",
       "      <td>0.744176</td>\n",
       "      <td>0.792611</td>\n",
       "      <td>0.483154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.352746</td>\n",
       "      <td>0.588804</td>\n",
       "      <td>0.404354</td>\n",
       "      <td>0.391265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219141</td>\n",
       "      <td>0.316855</td>\n",
       "      <td>0.104997</td>\n",
       "      <td>0.422342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.661438</td>\n",
       "      <td>0.485857</td>\n",
       "      <td>0.738860</td>\n",
       "      <td>0.102217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.013455</td>\n",
       "      <td>0.257351</td>\n",
       "      <td>0.868043</td>\n",
       "      <td>0.413509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.417482</td>\n",
       "      <td>0.031578</td>\n",
       "      <td>0.337873</td>\n",
       "      <td>0.144518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.520585</td>\n",
       "      <td>0.654922</td>\n",
       "      <td>0.126455</td>\n",
       "      <td>0.616839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.581897</td>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.727973</td>\n",
       "      <td>0.830095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.900494</td>\n",
       "      <td>0.030310</td>\n",
       "      <td>0.202013</td>\n",
       "      <td>0.399285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.704471</td>\n",
       "      <td>0.813321</td>\n",
       "      <td>0.862429</td>\n",
       "      <td>0.344971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.418720</td>\n",
       "      <td>0.004539</td>\n",
       "      <td>0.505358</td>\n",
       "      <td>0.931148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.658997</td>\n",
       "      <td>0.608391</td>\n",
       "      <td>0.101166</td>\n",
       "      <td>0.881753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.363557</td>\n",
       "      <td>0.405741</td>\n",
       "      <td>0.610332</td>\n",
       "      <td>0.891676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.273678</td>\n",
       "      <td>0.541985</td>\n",
       "      <td>0.585266</td>\n",
       "      <td>0.598478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.701861</td>\n",
       "      <td>0.570724</td>\n",
       "      <td>0.089177</td>\n",
       "      <td>0.618180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.586715</td>\n",
       "      <td>0.599143</td>\n",
       "      <td>0.200613</td>\n",
       "      <td>0.187981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.986905</td>\n",
       "      <td>0.988455</td>\n",
       "      <td>0.803123</td>\n",
       "      <td>0.430194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.092717</td>\n",
       "      <td>0.250469</td>\n",
       "      <td>0.680692</td>\n",
       "      <td>0.423106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3\n",
       "0   0.248782  0.876835  0.806854  0.020668\n",
       "1  -0.057214  0.828857  0.617800  0.550427\n",
       "2   0.735268  0.744176  0.792611  0.483154\n",
       "3   0.352746  0.588804  0.404354  0.391265\n",
       "4   0.219141  0.316855  0.104997  0.422342\n",
       "5   0.661438  0.485857  0.738860  0.102217\n",
       "6   1.013455  0.257351  0.868043  0.413509\n",
       "7   0.417482  0.031578  0.337873  0.144518\n",
       "8   0.520585  0.654922  0.126455  0.616839\n",
       "9   0.581897  0.978328  0.727973  0.830095\n",
       "10  0.900494  0.030310  0.202013  0.399285\n",
       "11  0.704471  0.813321  0.862429  0.344971\n",
       "12  0.418720  0.004539  0.505358  0.931148\n",
       "13  0.658997  0.608391  0.101166  0.881753\n",
       "14  0.363557  0.405741  0.610332  0.891676\n",
       "15  0.273678  0.541985  0.585266  0.598478\n",
       "16  0.701861  0.570724  0.089177  0.618180\n",
       "17  0.586715  0.599143  0.200613  0.187981\n",
       "18  0.986905  0.988455  0.803123  0.430194\n",
       "19  0.092717  0.250469  0.680692  0.423106"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_train, mlp_val = train_test_split(train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_train = mlp_train.to_numpy()\n",
    "mlp_val = mlp_val.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(4,40)\n",
    "        self.fc2 = torch.nn.Linear(40,30)\n",
    "        self.fc3 = torch.nn.Linear(30,20)\n",
    "        self.fc4 = torch.nn.Linear(20,2)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        out1 = F.tanh(self.fc1(X))\n",
    "        out2 = F.tanh(self.fc2(out1))\n",
    "        out3 = F.tanh(self.fc3(out2))\n",
    "        predict = F.softmax(self.fc4(out3))\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=4, out_features=40, bias=True)\n",
      "  (fc2): Linear(in_features=40, out_features=30, bias=True)\n",
      "  (fc3): Linear(in_features=30, out_features=20, bias=True)\n",
      "  (fc4): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_tensor = torch.tensor(mlp_train[:,0:4].copy())\n",
    "train_output_tensor = torch.tensor(mlp_train[:,4:6].copy())\n",
    "val_input_tensor = torch.tensor(mlp_val[:,0:4].copy())\n",
    "val_output_tensor = torch.tensor(mlp_val[:,4:6].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([135, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([135, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.2340\n",
      "Epoch:  10 | train loss: 0.2262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "C:\\Users\\yaoqi\\AppData\\Local\\Temp/ipykernel_19952/2803515142.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predict = F.softmax(self.fc4(out3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20 | train loss: 0.2219\n",
      "Epoch:  30 | train loss: 0.2078\n",
      "Epoch:  40 | train loss: 0.1796\n",
      "Epoch:  50 | train loss: 0.1632\n",
      "Epoch:  60 | train loss: 0.1360\n",
      "Epoch:  70 | train loss: 0.1023\n",
      "Epoch:  80 | train loss: 0.0740\n",
      "Epoch:  90 | train loss: 0.0564\n",
      "Epoch:  100 | train loss: 0.0381\n",
      "Epoch:  110 | train loss: 0.0270\n",
      "Epoch:  120 | train loss: 0.0217\n",
      "Epoch:  130 | train loss: 0.0185\n",
      "Epoch:  140 | train loss: 0.0163\n",
      "Epoch:  150 | train loss: 0.0145\n",
      "Epoch:  160 | train loss: 0.0125\n",
      "Epoch:  170 | train loss: 0.0072\n",
      "Epoch:  180 | train loss: 0.0040\n",
      "Epoch:  190 | train loss: 0.0022\n",
      "Epoch:  200 | train loss: 0.0013\n",
      "Epoch:  210 | train loss: 0.0009\n",
      "Epoch:  220 | train loss: 0.0006\n",
      "Epoch:  230 | train loss: 0.0005\n",
      "Epoch:  240 | train loss: 0.0004\n",
      "Epoch:  250 | train loss: 0.0003\n",
      "Epoch:  260 | train loss: 0.0003\n",
      "Epoch:  270 | train loss: 0.0003\n",
      "Epoch:  280 | train loss: 0.0002\n",
      "Epoch:  290 | train loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 300\n",
    "#BATCH_SIZE = 10\n",
    "LR = 0.02\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "error = pd.DataFrame(columns=['epoch', 'error'])\n",
    "\n",
    "# start training and illustrate the\n",
    "for epoch in range(EPOCH):\n",
    "    # input data to predict\n",
    "    prediction = model(train_input_tensor.float())\n",
    "    \n",
    "    # error between expected data and predicted data, pay attention on consequence\n",
    "    # first is predicted, second is real value\n",
    "    loss = loss_func(prediction, train_output_tensor.float())\n",
    "    \n",
    "    # start optimization\n",
    "    # set gradient as 0 before each optimization\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # error packpropogation\n",
    "    loss.backward()\n",
    "    \n",
    "    # optimize parameters based on minimum loss\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch > 0:\n",
    "        error = error.append(pd.DataFrame({'epoch':[epoch], 'error':[loss.data.numpy()]}))\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: ', epoch, '| train loss: %.4f' % loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.25432786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.23143417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.23881508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.23259243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.23030117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>295</td>\n",
       "      <td>0.00018705899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>296</td>\n",
       "      <td>0.00018505836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297</td>\n",
       "      <td>0.00018309239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>298</td>\n",
       "      <td>0.00018116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>0.00017926031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch          error\n",
       "0      1     0.25432786\n",
       "0      2     0.23143417\n",
       "0      3     0.23881508\n",
       "0      4     0.23259243\n",
       "0      5     0.23030117\n",
       "..   ...            ...\n",
       "0    295  0.00018705899\n",
       "0    296  0.00018505836\n",
       "0    297  0.00018309239\n",
       "0    298     0.00018116\n",
       "0    299  0.00017926031\n",
       "\n",
       "[299 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x243da9c9610>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.set_ylabel('Error', fontsize=20)\n",
    "ax.set_xlabel('Epoch', fontsize=20)\n",
    "plt.tick_params(labelsize=20)\n",
    "ax.scatter(error['epoch'],error['error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-proccessing on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "C:\\Users\\yaoqi\\AppData\\Local\\Temp/ipykernel_19952/2803515142.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predict = F.softmax(self.fc4(out3))\n"
     ]
    }
   ],
   "source": [
    "prediction = model(train_input_tensor.float())\n",
    "prediction = prediction.detach().numpy()\n",
    "#prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(prediction.shape[0]):\n",
    "    if prediction[i,0] > prediction[i,1]:\n",
    "        prediction[i,0] = 1\n",
    "        prediction[i,1] = 0\n",
    "    else:\n",
    "        prediction[i,0] = 0\n",
    "        prediction[i,1] = 1\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of errors we meet after training:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The number of errors we meet after training:')\n",
    "np.sum(np.absolute(prediction - mlp_train[:,4:6]))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix of training set is:\n",
      "[[85.  0.]\n",
      " [ 0. 50.]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cmat = np.zeros((2,2))\n",
    "for i in range(prediction.shape[0]):\n",
    "    cmat[int(prediction[i,0]),int(mlp_train[i,4])] += 1\n",
    "print('The confusion matrix of training set is:')\n",
    "print(cmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaoqi\\AppData\\Local\\Temp/ipykernel_19952/2803515142.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predict = F.softmax(self.fc4(out3))\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "prediction = model(val_input_tensor.float())\n",
    "prediction = prediction.detach().numpy()\n",
    "#prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of errors we meet after training:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(prediction.shape[0]):\n",
    "    if prediction[i,0] > prediction[i,1]:\n",
    "        prediction[i,0] = 1\n",
    "        prediction[i,1] = 0\n",
    "    else:\n",
    "        prediction[i,0] = 0\n",
    "        prediction[i,1] = 1\n",
    "print('The number of errors we meet after training:')\n",
    "np.sum(np.absolute(prediction - mlp_val[:,4:6]))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix of training set is:\n",
      "[[5. 5.]\n",
      " [1. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cmat = np.zeros((2,2))\n",
    "for i in range(prediction.shape[0]):\n",
    "    cmat[int(prediction[i,0]),int(mlp_val[i,4])] += 1\n",
    "print('The confusion matrix of training set is:')\n",
    "print(cmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_tensor = torch.tensor(test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.248782</td>\n",
       "      <td>0.876835</td>\n",
       "      <td>0.806854</td>\n",
       "      <td>0.020668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.057214</td>\n",
       "      <td>0.828857</td>\n",
       "      <td>0.617800</td>\n",
       "      <td>0.550427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.735268</td>\n",
       "      <td>0.744176</td>\n",
       "      <td>0.792611</td>\n",
       "      <td>0.483154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.352746</td>\n",
       "      <td>0.588804</td>\n",
       "      <td>0.404354</td>\n",
       "      <td>0.391265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219141</td>\n",
       "      <td>0.316855</td>\n",
       "      <td>0.104997</td>\n",
       "      <td>0.422342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.661438</td>\n",
       "      <td>0.485857</td>\n",
       "      <td>0.738860</td>\n",
       "      <td>0.102217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.013455</td>\n",
       "      <td>0.257351</td>\n",
       "      <td>0.868043</td>\n",
       "      <td>0.413509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.417482</td>\n",
       "      <td>0.031578</td>\n",
       "      <td>0.337873</td>\n",
       "      <td>0.144518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.520585</td>\n",
       "      <td>0.654922</td>\n",
       "      <td>0.126455</td>\n",
       "      <td>0.616839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.581897</td>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.727973</td>\n",
       "      <td>0.830095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.900494</td>\n",
       "      <td>0.030310</td>\n",
       "      <td>0.202013</td>\n",
       "      <td>0.399285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.704471</td>\n",
       "      <td>0.813321</td>\n",
       "      <td>0.862429</td>\n",
       "      <td>0.344971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.418720</td>\n",
       "      <td>0.004539</td>\n",
       "      <td>0.505358</td>\n",
       "      <td>0.931148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.658997</td>\n",
       "      <td>0.608391</td>\n",
       "      <td>0.101166</td>\n",
       "      <td>0.881753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.363557</td>\n",
       "      <td>0.405741</td>\n",
       "      <td>0.610332</td>\n",
       "      <td>0.891676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.273678</td>\n",
       "      <td>0.541985</td>\n",
       "      <td>0.585266</td>\n",
       "      <td>0.598478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.701861</td>\n",
       "      <td>0.570724</td>\n",
       "      <td>0.089177</td>\n",
       "      <td>0.618180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.586715</td>\n",
       "      <td>0.599143</td>\n",
       "      <td>0.200613</td>\n",
       "      <td>0.187981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.986905</td>\n",
       "      <td>0.988455</td>\n",
       "      <td>0.803123</td>\n",
       "      <td>0.430194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.092717</td>\n",
       "      <td>0.250469</td>\n",
       "      <td>0.680692</td>\n",
       "      <td>0.423106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3\n",
       "0   0.248782  0.876835  0.806854  0.020668\n",
       "1  -0.057214  0.828857  0.617800  0.550427\n",
       "2   0.735268  0.744176  0.792611  0.483154\n",
       "3   0.352746  0.588804  0.404354  0.391265\n",
       "4   0.219141  0.316855  0.104997  0.422342\n",
       "5   0.661438  0.485857  0.738860  0.102217\n",
       "6   1.013455  0.257351  0.868043  0.413509\n",
       "7   0.417482  0.031578  0.337873  0.144518\n",
       "8   0.520585  0.654922  0.126455  0.616839\n",
       "9   0.581897  0.978328  0.727973  0.830095\n",
       "10  0.900494  0.030310  0.202013  0.399285\n",
       "11  0.704471  0.813321  0.862429  0.344971\n",
       "12  0.418720  0.004539  0.505358  0.931148\n",
       "13  0.658997  0.608391  0.101166  0.881753\n",
       "14  0.363557  0.405741  0.610332  0.891676\n",
       "15  0.273678  0.541985  0.585266  0.598478\n",
       "16  0.701861  0.570724  0.089177  0.618180\n",
       "17  0.586715  0.599143  0.200613  0.187981\n",
       "18  0.986905  0.988455  0.803123  0.430194\n",
       "19  0.092717  0.250469  0.680692  0.423106"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "C:\\Users\\yaoqi\\AppData\\Local\\Temp/ipykernel_19952/2803515142.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predict = F.softmax(self.fc4(out3))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0092394e-08, 1.0000000e+00],\n",
       "       [7.1091478e-07, 9.9999928e-01],\n",
       "       [6.5680681e-04, 9.9934322e-01],\n",
       "       [4.4079153e-03, 9.9559206e-01],\n",
       "       [9.9991679e-01, 8.3148734e-05],\n",
       "       [9.9996579e-01, 3.4256533e-05],\n",
       "       [9.5123160e-01, 4.8768390e-02],\n",
       "       [9.9964368e-01, 3.5633278e-04],\n",
       "       [9.8623812e-01, 1.3761877e-02],\n",
       "       [5.1464154e-03, 9.9485356e-01],\n",
       "       [1.7445565e-04, 9.9982554e-01],\n",
       "       [9.9809688e-01, 1.9030763e-03],\n",
       "       [9.9997616e-01, 2.3824879e-05],\n",
       "       [1.7871274e-07, 9.9999988e-01],\n",
       "       [9.1791445e-01, 8.2085550e-02],\n",
       "       [1.7766207e-01, 8.2233787e-01],\n",
       "       [2.2359261e-06, 9.9999774e-01],\n",
       "       [1.3270065e-01, 8.6729938e-01],\n",
       "       [3.5974868e-02, 9.6402508e-01],\n",
       "       [1.0970445e-04, 9.9989033e-01]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model(test_input_tensor.float())\n",
    "prediction = prediction.detach().numpy()\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(prediction.shape[0]):\n",
    "    if prediction[i,0] > prediction[i,1]:\n",
    "        prediction[i,0] = 1\n",
    "        prediction[i,1] = 0\n",
    "    else:\n",
    "        prediction[i,0] = 0\n",
    "        prediction[i,1] = 1\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('ctest.csv', header = None)\n",
    "test['4'] = None\n",
    "test['4'] = prediction[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final answer for the testing section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.248782</td>\n",
       "      <td>0.876835</td>\n",
       "      <td>0.806854</td>\n",
       "      <td>0.020668</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.057214</td>\n",
       "      <td>0.828857</td>\n",
       "      <td>0.617800</td>\n",
       "      <td>0.550427</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.735268</td>\n",
       "      <td>0.744176</td>\n",
       "      <td>0.792611</td>\n",
       "      <td>0.483154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.352746</td>\n",
       "      <td>0.588804</td>\n",
       "      <td>0.404354</td>\n",
       "      <td>0.391265</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219141</td>\n",
       "      <td>0.316855</td>\n",
       "      <td>0.104997</td>\n",
       "      <td>0.422342</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.661438</td>\n",
       "      <td>0.485857</td>\n",
       "      <td>0.738860</td>\n",
       "      <td>0.102217</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.013455</td>\n",
       "      <td>0.257351</td>\n",
       "      <td>0.868043</td>\n",
       "      <td>0.413509</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.417482</td>\n",
       "      <td>0.031578</td>\n",
       "      <td>0.337873</td>\n",
       "      <td>0.144518</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.520585</td>\n",
       "      <td>0.654922</td>\n",
       "      <td>0.126455</td>\n",
       "      <td>0.616839</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.581897</td>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.727973</td>\n",
       "      <td>0.830095</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.900494</td>\n",
       "      <td>0.030310</td>\n",
       "      <td>0.202013</td>\n",
       "      <td>0.399285</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.704471</td>\n",
       "      <td>0.813321</td>\n",
       "      <td>0.862429</td>\n",
       "      <td>0.344971</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.418720</td>\n",
       "      <td>0.004539</td>\n",
       "      <td>0.505358</td>\n",
       "      <td>0.931148</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.658997</td>\n",
       "      <td>0.608391</td>\n",
       "      <td>0.101166</td>\n",
       "      <td>0.881753</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.363557</td>\n",
       "      <td>0.405741</td>\n",
       "      <td>0.610332</td>\n",
       "      <td>0.891676</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.273678</td>\n",
       "      <td>0.541985</td>\n",
       "      <td>0.585266</td>\n",
       "      <td>0.598478</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.701861</td>\n",
       "      <td>0.570724</td>\n",
       "      <td>0.089177</td>\n",
       "      <td>0.618180</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.586715</td>\n",
       "      <td>0.599143</td>\n",
       "      <td>0.200613</td>\n",
       "      <td>0.187981</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.986905</td>\n",
       "      <td>0.988455</td>\n",
       "      <td>0.803123</td>\n",
       "      <td>0.430194</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.092717</td>\n",
       "      <td>0.250469</td>\n",
       "      <td>0.680692</td>\n",
       "      <td>0.423106</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3    4\n",
       "0   0.248782  0.876835  0.806854  0.020668  0.0\n",
       "1  -0.057214  0.828857  0.617800  0.550427  0.0\n",
       "2   0.735268  0.744176  0.792611  0.483154  0.0\n",
       "3   0.352746  0.588804  0.404354  0.391265  0.0\n",
       "4   0.219141  0.316855  0.104997  0.422342  1.0\n",
       "5   0.661438  0.485857  0.738860  0.102217  1.0\n",
       "6   1.013455  0.257351  0.868043  0.413509  1.0\n",
       "7   0.417482  0.031578  0.337873  0.144518  1.0\n",
       "8   0.520585  0.654922  0.126455  0.616839  1.0\n",
       "9   0.581897  0.978328  0.727973  0.830095  0.0\n",
       "10  0.900494  0.030310  0.202013  0.399285  0.0\n",
       "11  0.704471  0.813321  0.862429  0.344971  1.0\n",
       "12  0.418720  0.004539  0.505358  0.931148  1.0\n",
       "13  0.658997  0.608391  0.101166  0.881753  0.0\n",
       "14  0.363557  0.405741  0.610332  0.891676  1.0\n",
       "15  0.273678  0.541985  0.585266  0.598478  0.0\n",
       "16  0.701861  0.570724  0.089177  0.618180  0.0\n",
       "17  0.586715  0.599143  0.200613  0.187981  0.0\n",
       "18  0.986905  0.988455  0.803123  0.430194  0.0\n",
       "19  0.092717  0.250469  0.680692  0.423106  0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
